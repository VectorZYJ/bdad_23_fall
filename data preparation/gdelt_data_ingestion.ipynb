{
  "metadata": {
    "name": "Data Ingestion",
    "kernelspec": {
      "language": "scala",
      "name": "spark2-scala"
    },
    "language_info": {
      "codemirror_mode": "text/x-scala",
      "file_extension": ".scala",
      "mimetype": "text/x-scala",
      "name": "scala",
      "pygments_lexer": "scala"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2,
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val filePath \u003d \"GDELT_data/20180101.csv\"\n\nval rawDF \u003d spark.read\n  .option(\"header\", \"true\")\n  .option(\"multiLine\", \"true\")\n  .option(\"inferSchema\", \"true\")\n  .option(\"escape\", \"\\\"\")\n  .csv(filePath)\n\nz.show(rawDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val baseDF \u003d rawDF.select(\n  \"DATEADDED\",\n  \"CAMEOCodeDescription\",\n  \"AvgTone\",\n  \"SOURCEURL\")\n\nz.show(baseDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val distinctDF \u003d baseDF.dropDuplicates(\"SOURCEURL\")\n\ndistinctDF.printSchema\nz.show(distinctDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val finalDF \u003d distinctDF.withColumn(\"DateStr\", col(\"DATEADDED\").cast(\"string\"))\n    .drop(\"DATEADDED\")\n    .withColumn(\"Date\", to_date(col(\"DateStr\"), \"yyyyMMdd\"))\n    .drop(\"DateStr\")\n    .withColumnRenamed(\"CAMEOCodeDescription\", \"Type\")\n    .withColumnRenamed(\"AvgTone\", \"Tone\")\n    .withColumnRenamed(\"SOURCEURL\", \"Url\")\n    .select(\"Date\", \"Tone\", \"Type\", \"Url\")\n    .na.drop()\n\nfinalDF.printSchema\nz.show(finalDF)"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "autoscroll": "auto"
      },
      "outputs": [],
      "source": "val outputPath \u003d \"20180101.parquet\"\n\nfinalDF.write.mode(\"overwrite\").parquet(outputPath)"
    }
  ]
}